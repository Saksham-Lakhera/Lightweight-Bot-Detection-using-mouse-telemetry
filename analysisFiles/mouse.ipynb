{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Our mouse telemetry detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract and preporcess mouse movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is not copied here, Please chose your own dataset and Use this file just as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will not work as we don't have dataset for it to train in this git reprository as Git has some space limitation for free tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_coordinates(coord_str):\n",
    "    return re.findall(r'\\[(\\d+),(\\d+)\\]', coord_str)\n",
    "\n",
    "def parse_timestamps(timestamps_str):\n",
    "    return timestamps_str.strip(',').split(',')\n",
    "\n",
    "def process_file(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    session_id = data.get(\"session_id\")\n",
    "    coords_raw = data.get(\"mousemove_total_behaviour\", \"\")\n",
    "    times_raw = data.get(\"mousemove_times\", \"\")\n",
    "    \n",
    "    coords = parse_coordinates(coords_raw)\n",
    "    times = parse_timestamps(times_raw)\n",
    "    \n",
    "    # Ensure equal length\n",
    "    length = min(len(coords), len(times))\n",
    "    coords = coords[:length]\n",
    "    times = times[:length]\n",
    "    \n",
    "    records = []\n",
    "    for i in range(length):\n",
    "        x, y = coords[i]\n",
    "        timestamp = times[i]\n",
    "        records.append({\n",
    "            \"session_id\": session_id,\n",
    "            \"timestamp\": int(timestamp),\n",
    "            \"x\": int(x),\n",
    "            \"y\": int(y)\n",
    "        })\n",
    "    \n",
    "    return records\n",
    "\n",
    "def read_all_jsons(root_dir):\n",
    "    all_records = []\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    records = process_file(filepath)\n",
    "                    all_records.extend(records)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {filepath}: {e}\")\n",
    "    return pd.DataFrame(all_records)\n",
    "\n",
    "# Example usage\n",
    "root_directory = './phase1/data/mouse_movements'\n",
    "df = read_all_jsons(root_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vj/mbznbr_s7fb1cqsqnx00ch_m0000gn/T/ipykernel_63802/3597982624.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  label_df = pd.read_csv(\"./phase1/final\", delim_whitespace=True, header=None, names=[\"session_id\", \"label\"])\n"
     ]
    }
   ],
   "source": [
    "label_df = pd.read_csv(\"./phase1/final\", delim_whitespace=True, header=None, names=[\"session_id\", \"label\"])\n",
    "label_map = dict(zip(label_df[\"session_id\"], label_df[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "human           1071630\n",
      "advanced_bot     368340\n",
      "moderate_bot     199026\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"label\"] = df[\"session_id\"].map(label_map)\n",
    "print(df[\"label\"].value_counts())  # Check how many humans vs bots\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         session_id  timestamp   x    y  label\n",
      "0        v3hbnujku5f0bm2mmbjqrr9rg8  621539491   7    6      1\n",
      "1        v3hbnujku5f0bm2mmbjqrr9rg8  621539502  15   14      1\n",
      "2        v3hbnujku5f0bm2mmbjqrr9rg8  621539518  23   22      1\n",
      "3        v3hbnujku5f0bm2mmbjqrr9rg8  621539535  31   30      1\n",
      "4        v3hbnujku5f0bm2mmbjqrr9rg8  621539552  39   38      1\n",
      "...                             ...        ...  ..  ...    ...\n",
      "1595686  vllcsfvm4m4b6559eckqpg3mvq  445334161  45  183      1\n",
      "1595687  vllcsfvm4m4b6559eckqpg3mvq  445334177  44  183      1\n",
      "1595688  vllcsfvm4m4b6559eckqpg3mvq  445334194  43  183      1\n",
      "1595689  vllcsfvm4m4b6559eckqpg3mvq  445334211  42  182      1\n",
      "1595690  vllcsfvm4m4b6559eckqpg3mvq  445334227  42  182      1\n",
      "\n",
      "[1103181 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'human' to 0, everything else to 1\n",
    "df['label'] = df['label'].apply(lambda x: 0 if str(x).strip().lower() == 'human' else 1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    567366\n",
      "0    535815\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"label\"].value_counts())  # Check how many humans vs bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions processed: 150\n",
      "Sessions skipped (too short): 0\n",
      "Total sequences created: 1100331\n"
     ]
    }
   ],
   "source": [
    "def create_sequences_with_labels(df, seq_length=20):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    session_count = 0\n",
    "    total_skipped = 0\n",
    "\n",
    "    # Clean session_id\n",
    "    df[\"session_id\"] = df[\"session_id\"].astype(str).str.strip()\n",
    "    for session_id, group in df.groupby(\"session_id\"):\n",
    "        session_count += 1\n",
    "        group = group.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "        if len(group) < seq_length:\n",
    "            total_skipped += 1\n",
    "            continue\n",
    "\n",
    "        group = group.copy()\n",
    "        group[\"dt\"] = group[\"timestamp\"].diff().fillna(0).astype(float)\n",
    "        data = group[[\"x\", \"y\", \"dt\"]].values\n",
    "        label = group[\"label\"].iloc[0]  # same for entire session\n",
    "\n",
    "        for i in range(len(data) - seq_length + 1):\n",
    "            sequences.append(data[i:i+seq_length].copy())\n",
    "            labels.append(label)\n",
    "\n",
    "    print(f\"Sessions processed: {session_count}\")\n",
    "    print(f\"Sessions skipped (too short): {total_skipped}\")\n",
    "    print(f\"Total sequences created: {len(sequences)}\")\n",
    "\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Example usage\n",
    "sequences, y = create_sequences_with_labels(df, seq_length=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1100331, 20, 3)\n",
      "y shape: (1100331,)\n",
      "y sample: {np.int64(0), np.int64(1)}\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", sequences.shape)  # (num_sequences, seq_length, 3)\n",
    "print(\"y shape:\", y.shape)          # (num_sequences,)\n",
    "print(\"y sample:\", set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sequence_minmax(seq):\n",
    "    # seq: (20, 3) â€” one sequence\n",
    "    seq = seq.astype(np.float32)\n",
    "    normalized = np.zeros_like(seq)\n",
    "    eps = 1e-8  # avoid divide by zero\n",
    "    for i in range(seq.shape[1]):  # for each column (x, y, dt)\n",
    "        col = seq[:, i]\n",
    "        col_min = np.min(col)\n",
    "        col_max = np.max(col)\n",
    "        normalized[:, i] = (col - col_min) / (col_max - col_min + eps)\n",
    "\n",
    "    return normalized\n",
    "sequences = np.array([normalize_sequence_minmax(seq) for seq in sequences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our new sequence structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         0.         0.        ]\n",
      "  [0.05517241 0.05263158 0.47058824]\n",
      "  [0.10344828 0.10526316 0.9411765 ]\n",
      "  ...\n",
      "  [0.8965517  0.8947368  0.9411765 ]\n",
      "  [0.9517241  0.94736844 1.        ]\n",
      "  [1.         1.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.04827586 0.05263158 0.8888889 ]\n",
      "  [0.10344828 0.10526316 1.        ]\n",
      "  ...\n",
      "  [0.8965517  0.8947368  1.        ]\n",
      "  [0.94482756 0.94736844 1.        ]\n",
      "  [1.         1.         0.8888889 ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.05517241 0.05263158 1.        ]\n",
      "  [0.11034483 0.10526316 1.        ]\n",
      "  ...\n",
      "  [0.8965517  0.8947368  1.        ]\n",
      "  [0.9517241  0.94736844 0.        ]\n",
      "  [1.         1.         1.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.         0.         1.        ]\n",
      "  [0.9354839  0.06796116 1.        ]\n",
      "  [0.87096775 0.13592233 0.        ]\n",
      "  ...\n",
      "  [0.01612903 0.98058254 0.        ]\n",
      "  [0.00806452 0.99029124 1.        ]\n",
      "  [0.         1.         1.        ]]\n",
      "\n",
      " [[1.         0.         1.        ]\n",
      "  [0.93162394 0.07216495 0.        ]\n",
      "  [0.8632479  0.13402061 1.        ]\n",
      "  ...\n",
      "  [0.01709402 0.97938144 1.        ]\n",
      "  [0.00854701 0.9896907  1.        ]\n",
      "  [0.         1.         0.        ]]\n",
      "\n",
      " [[1.         0.         0.        ]\n",
      "  [0.9266055  0.06666667 0.00502513]\n",
      "  [0.853211   0.14444445 0.00502513]\n",
      "  ...\n",
      "  [0.00917431 0.98888886 0.00502513]\n",
      "  [0.         1.         0.        ]\n",
      "  [0.         1.         1.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "Batch X shape: torch.Size([512, 20, 3])\n",
      "Batch y shape: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(sequences, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Create full dataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split lengths\n",
    "total_len = len(dataset)\n",
    "train_len = int(0.9 * total_len)\n",
    "test_len = int(0.05 * total_len)\n",
    "val_len = total_len - train_len - test_len\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Optional sanity check\n",
    "for xb, yb in train_loader:\n",
    "    print(\"Batch X shape:\", xb.shape)  # (batch_size, seq_length, 3)\n",
    "    print(\"Batch y shape:\", yb.shape)  # (batch_size,)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use your own method for preprocessing the data; the code above is meant for that purpose. You can then modify the code below to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device selection for better training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# 3. Device Setup\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our LSTM based model that is to be deployed for anti scrapper/bot detection tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=16, lstm_layers=1, fc_dims=[3,1], seq_len=20):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, fc_dims[0])\n",
    "        self.fc2 = nn.Linear(fc_dims[0], fc_dims[1])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()  # for binary classification output\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        h_forward = h_n[-2]\n",
    "        h_backward = h_n[-1]\n",
    "        h_combined = torch.cat((h_forward, h_backward), dim=1)  # (batch, hidden_dim * 2)\n",
    "\n",
    "        out = self.relu(self.fc1(h_combined))\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(\n",
    "    input_dim=3, \n",
    "    hidden_dim=32, \n",
    "    lstm_layers=1,\n",
    "    fc_dims=[2, 1],\n",
    "    seq_len=20\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.float().to(device)\n",
    "        output = model(xb).squeeze()\n",
    "        loss = criterion(output, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        preds = (output >= 0.5).float()\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def validate_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.float().to(device)\n",
    "            output = model(xb).squeeze()\n",
    "            loss = criterion(output, yb)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Accuracy calculation\n",
    "            preds = (output >= 0.5).float()\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Scheduler\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)  # Halve LR every 20 epochs\n",
    "\n",
    "# -------------------------\n",
    "# 2. Training Loop with Scheduler\n",
    "epochs = 40\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader)\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader)\n",
    "\n",
    "    print(f\"[Epoch {epoch:02d}] \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weightsless.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_with_report_and_confusion(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_inputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb_device = xb.to(device)\n",
    "            output = model(xb_device).squeeze().cpu()\n",
    "            preds = (output >= 0.5).int()\n",
    "\n",
    "            all_inputs.extend(xb.cpu())      # Save for later plotting\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_targets.extend(yb.tolist())\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nðŸ“Š Classification Report:\")\n",
    "    print(classification_report(all_targets, all_preds, target_names=[\"Human (0)\", \"Bot (1)\"]))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"Human (0)\", \"Bot (1)\"],\n",
    "                yticklabels=[\"Human (0)\", \"Bot (1)\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"ðŸ§© Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return all_inputs, all_targets, all_preds\n",
    "\n",
    "def visualize_confusion_examples(all_inputs, all_targets, all_preds, max_samples=5):\n",
    "    categories = {\n",
    "        \"True Positive (Bot Correct)\": [],\n",
    "        \"True Negative (Human Correct)\": [],\n",
    "        \"False Positive (Human â†’ Bot)\": [],\n",
    "        \"False Negative (Bot â†’ Human)\": [],\n",
    "    }\n",
    "\n",
    "    for x, true, pred in zip(all_inputs, all_targets, all_preds):\n",
    "        if true == 1 and pred == 1:\n",
    "            categories[\"True Positive (Bot Correct)\"].append(x)\n",
    "        elif true == 0 and pred == 0:\n",
    "            categories[\"True Negative (Human Correct)\"].append(x)\n",
    "        elif true == 0 and pred == 1:\n",
    "            categories[\"False Positive (Human â†’ Bot)\"].append(x)\n",
    "        elif true == 1 and pred == 0:\n",
    "            categories[\"False Negative (Bot â†’ Human)\"].append(x)\n",
    "\n",
    "    # Plot sequences\n",
    "    for title, samples in categories.items():\n",
    "        print(f\"\\nðŸ“Œ {title} â€” Showing {min(max_samples, len(samples))} samples:\")\n",
    "        selected = random.sample(samples, min(max_samples, len(samples)))\n",
    "        for i, seq in enumerate(selected, 1):\n",
    "            x_vals = seq[:, 0]\n",
    "            y_vals = seq[:, 1]\n",
    "            plt.plot(x_vals, y_vals, marker='o')\n",
    "            plt.title(f\"{title} #{i}\")\n",
    "            plt.xlabel(\"x\")\n",
    "            plt.ylabel(\"y\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out client side model that will work on Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(JSModel, self).__init__()\n",
    "        self.lstm = original_model.lstm\n",
    "        self.fc1 = original_model.fc1\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        h_forward = h_n[-2]\n",
    "        h_backward = h_n[-1]\n",
    "        h_combined = torch.cat((h_forward, h_backward), dim=1)\n",
    "        out = self.relu(self.fc1(h_combined))\n",
    "        return out\n",
    "\n",
    "dummy_input = torch.randn(1, 20, 3)  # (batch, seq_len, features)\n",
    "js_model = JSModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The js_model.onnx will be used by JS to capture latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(js_model, dummy_input, \"js_model.onnx\", input_names=[\"input\"], output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get server model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalClassifier(\n",
       "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FinalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FinalClassifier, self).__init__()\n",
    "        self.fc2 = nn.Linear(2, 1)   # because JS sends 5 latent values\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.fc2(x))\n",
    "\n",
    "\n",
    "state_dict = torch.load('model_weightsless.pth', map_location=device)\n",
    "\n",
    "# Extract only fc2 weights\n",
    "fc2_state_dict = {k.replace('fc2.', ''): v for k, v in state_dict.items() if k.startswith('fc2.')}\n",
    "\n",
    "model = FinalClassifier().to(device)\n",
    "model.fc2.load_state_dict(fc2_state_dict)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only save last layer\n",
    "torch.save(model.fc2.state_dict(), 'server_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
